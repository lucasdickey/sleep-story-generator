/**
 * generateEpisode.ts
 *
 * Parent script to generate a Key To Sleep podcast episode (story, metadata, artwork prompt)
 * using OpenAI and modular stochastic prompts. Outputs are timestamped for uniqueness.
 * Lint-clean for CI/CD.
 *
 * This script runs the entire episode generation workflow, not just story generation.
 */

const fs = require('fs/promises');
const path = require('path');
const { config } = require('dotenv');
const { OpenAI } = require('openai');

// Load environment variables
config({ path: path.resolve(__dirname, '../.env.local') });

const STORY_PROMPT_FILE = path.resolve(__dirname, '../prompts/story.txt');
const METADATA_PROMPT_FILE = path.resolve(__dirname, '../prompts/metadata.txt');
const ARTWORK_PROMPT_FILE = path.resolve(__dirname, '../prompts/artwork.txt');
const OUTPUT_DIR = path.resolve(__dirname, '../output');

// Generate a unique episodeId using full ISO timestamp
function getEpisodeId(): string {
  const now = new Date();
  return now.toISOString().replace(/[:.]/g, '').replace('T', 'T').replace('Z', 'Z');
}

// Helper to read individual prompt files
async function readPrompt(filePath: string): Promise<string> {
  return (await fs.readFile(filePath, 'utf8')).trim();
}

async function encodeImageToDataUrl(imagePath: string): Promise<string> {
  const ext = path.extname(imagePath).slice(1).toLowerCase();
  // Fix for: Element implicitly has an 'any' type because expression of type 'any' can't be used to index type ... (lint ID: 80dc7687-32b1-403a-bcf3-d8619b5586dc)
  const mimeTypes: Record<string, string> = {
    png: 'image/png',
    jpg: 'image/jpeg',
    jpeg: 'image/jpeg',
    webp: 'image/webp',
    gif: 'image/gif'
  };
  const mimeType = mimeTypes[ext] || 'application/octet-stream';
  const buffer = await fs.readFile(imagePath);
  return `data:${mimeType};base64,${buffer.toString('base64')}`;
}

async function callOpenAI(prompt: string, userInput = '', systemMsg = 'You are a peaceful sleep story narrator for a podcast.'): Promise<string> {
  const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  const model = process.env.OPENAI_MODEL || 'gpt-4o';
  const messages: { role: 'system' | 'user' | 'assistant'; content: string }[] = [
    { role: 'system', content: systemMsg },
    { role: 'user', content: prompt + (userInput ? '\n' + userInput : '') }
  ];
  const completion = await openai.chat.completions.create({
    model,
    messages,
    temperature: 0.8,
    max_tokens: 1800,
  });
  return completion.choices[0]?.message.content?.trim() || '';
}

// Multimodal artwork generation using GPT-4o
async function callOpenAIMultimodalArtwork({
  prompt,
  userInput = '',
  systemMsg = 'You are a creative visual artist for a podcast.',
  imagePaths = []
}: {
  prompt: string;
  userInput?: string;
  systemMsg?: string;
  imagePaths: string[];
}): Promise<string> {
  const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  const model = process.env.OPENAI_MODEL || 'gpt-4o';
  const messages: any[] = [
    { role: 'system', content: systemMsg },
    // Images as separate user messages
    ...(
      await Promise.all(
        imagePaths.map(async (imgPath) => ({
          role: 'user',
          content: [
            {
              type: 'image_url',
              image_url: { url: await encodeImageToDataUrl(imgPath) }
            }
          ]
        }))
      )
    ),
    // The text prompt and user input as a user message
    {
      role: 'user',
      content: [
        { type: 'text', text: prompt + (userInput ? '\n' + userInput : '') }
      ]
    }
  ];
  const completion = await openai.chat.completions.create({
    model,
    messages,
    temperature: 0.8,
    max_tokens: 1800,
  });
  return completion.choices[0]?.message.content?.trim() || '';
}


async function main(): Promise<void> {
  try {
    await fs.mkdir(OUTPUT_DIR, { recursive: true });
    // Read prompts from separate files
    const storyPrompt = await readPrompt(STORY_PROMPT_FILE);
    // Dynamically read all reference scripts in prompts/reference_scripts
    const referenceDir = path.resolve(__dirname, '../prompts/reference_scripts');
    const referenceFiles = (await fs.readdir(referenceDir)).filter((f: string) => f.endsWith('.txt'));
    let referencesContent = '';
    for (const file of referenceFiles) {
      const refContent = await fs.readFile(path.join(referenceDir, file), 'utf8');
      referencesContent += `--- Reference Script: ${file} ---\n${refContent}\n\n`;
    }
    const combinedPrompt = `Here are reference scripts for inspiration (do not copy directly):\n\n${referencesContent}${storyPrompt}`;
    const metadataPrompt = await readPrompt(METADATA_PROMPT_FILE);
    const artworkPrompt = await readPrompt(ARTWORK_PROMPT_FILE);
    // Dynamically read all reference artwork images in prompts/reference_artwork
    const artworkReferenceDir = path.resolve(__dirname, '../prompts/reference_artwork');
    // Only filenames are referenced in the prompt for now. For true multimodal support, images should be sent directly to the model if supported.
    // TODO: When using a multimodal API, send the actual images as part of the input to the model.
    // Fix for: Parameter 'f' implicitly has an 'any' type. (lint ID: b17a5ad5-d2d6-4872-9e54-3c37b4db88f7)
    const artworkReferenceFiles = (await fs.readdir(artworkReferenceDir)).filter((f: string) => f.match(/\.(png|jpg|jpeg|webp|gif)$/i));
    let artworkReferencesContent = '';
    if (artworkReferenceFiles.length > 0) {
      artworkReferencesContent = 'Here are reference artwork images for inspiration (do not copy directly):\n' +
        artworkReferenceFiles.map((f: string) => `- prompts/reference_artwork/${f}`).join('\n') + '\n\n';
    }
    const combinedArtworkPrompt = `${artworkReferencesContent}${artworkPrompt}`;
    const episodeId = getEpisodeId();

    // 1. Generate story
    console.log('Generating sleep story...');
    const story = await callOpenAI(combinedPrompt);
    // Remove any lines or inline text in square brackets (e.g., [music], [Sound of ...])
    const storyFiltered = story
      .split('\n')
      .map(line => line.replace(/\[[^\]]*\]/g, '').trim())
      .filter(line => line.length > 0)
      .join('\n');
    await fs.writeFile(path.join(OUTPUT_DIR, `${episodeId}-story.txt`), storyFiltered, 'utf8');
    console.log(`Story saved to output/${episodeId}-story.txt`);

    // 2. Generate metadata
    console.log('Generating episode metadata...');
    const metadata = await callOpenAI(metadataPrompt, story);
    await fs.writeFile(path.join(OUTPUT_DIR, `${episodeId}-metadata.json`), metadata, 'utf8');
    console.log(`Metadata saved to output/${episodeId}-metadata.json`);

    // 3. Generate artwork prompt (multimodal)
    console.log('Generating artwork prompt...');
    const artworkInput = `${story}\n\n${metadata}`;
    // Build absolute paths for artwork images
    const artworkImagePaths = artworkReferenceFiles.map((f: string) => path.join(artworkReferenceDir, f));
    const artworkPromptText = await callOpenAIMultimodalArtwork({
      prompt: combinedArtworkPrompt,
      userInput: artworkInput,
      systemMsg: 'You are a creative visual artist for a podcast.',
      imagePaths: artworkImagePaths
    });
    await fs.writeFile(path.join(OUTPUT_DIR, `${episodeId}-artwork-prompt.txt`), artworkPromptText, 'utf8');
    console.log(`Artwork prompt saved to output/${episodeId}-artwork-prompt.txt`);
  } catch (err) {
    // eslint-disable-next-line no-console
    console.error('Error in story generation pipeline:', err);
    process.exit(1);
  }
}

main();
